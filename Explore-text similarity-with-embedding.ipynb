{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Day 2 - Classifying embeddings with Keras and the Gemini API\n\n## Overview\n\nWelcome back to the Kaggle 5-day Generative AI course. In this notebook, you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.\n\nThis technique uses the Gemini API's embeddings as input, avoiding the need to train on text input directly, and as a result it is able to perform quite well using relatively few examples compared to training a text model from scratch.\n\n## For help\n\n**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n","metadata":{}},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:21:00.352450Z","iopub.execute_input":"2025-01-06T21:21:00.352776Z","iopub.status.idle":"2025-01-06T21:21:25.425019Z","shell.execute_reply.started":"2025-01-06T21:21:00.352752Z","shell.execute_reply":"2025-01-06T21:21:25.423699Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:21:25.426818Z","iopub.execute_input":"2025-01-06T21:21:25.427235Z","iopub.status.idle":"2025-01-06T21:21:26.709423Z","shell.execute_reply.started":"2025-01-06T21:21:25.427193Z","shell.execute_reply":"2025-01-06T21:21:26.708255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up API Key\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:26:34.212548Z","iopub.execute_input":"2025-01-06T21:26:34.213195Z","iopub.status.idle":"2025-01-06T21:26:34.372362Z","shell.execute_reply.started":"2025-01-06T21:26:34.213161Z","shell.execute_reply":"2025-01-06T21:26:34.371366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Explore models\nfor model in genai.list_models():\n  if 'embedContent' in model.supported_generation_methods:\n    print(model.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:26:46.376786Z","iopub.execute_input":"2025-01-06T21:26:46.377174Z","iopub.status.idle":"2025-01-06T21:26:46.611209Z","shell.execute_reply.started":"2025-01-06T21:26:46.377145Z","shell.execute_reply":"2025-01-06T21:26:46.610111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate similarity scores between example sentences\n\ntexts = [\n    'The quick brown fox jumps over the lazy dog.',\n    'The quick rbown fox jumps over the lazy dog.',\n    'teh fast fox jumps over the slow woofer.',\n    'a quick brown fox jmps over lazy dog.',\n    'brown fox jumping over dog',\n    'fox > dog',\n    # Alternative pangram for comparison:\n    'The five boxing wizards jump quickly.',\n    # Unrelated text, also for comparison:\n    'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus et hendrerit massa. Sed pulvinar, nisi a lobortis sagittis, neque risus gravida dolor, in porta dui odio vel purus.',\n]\n\n\nresponse = genai.embed_content(model='models/text-embedding-004',\n                               content=texts,\n                               task_type='semantic_similarity')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:27:23.027404Z","iopub.execute_input":"2025-01-06T21:27:23.027782Z","iopub.status.idle":"2025-01-06T21:27:25.578331Z","shell.execute_reply.started":"2025-01-06T21:27:23.027755Z","shell.execute_reply":"2025-01-06T21:27:25.577166Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define function to display longer embedding texts in visualizations\ndef truncate(t: str, limit: int = 50) -> str:\n  \"\"\"Truncate labels to fit on the chart.\"\"\"\n  if len(t) > limit:\n    return t[:limit-3] + '...'\n  else:\n    return t\n\ntruncated_texts = [truncate(t) for t in texts]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:27:43.733245Z","iopub.execute_input":"2025-01-06T21:27:43.733607Z","iopub.status.idle":"2025-01-06T21:27:43.739672Z","shell.execute_reply.started":"2025-01-06T21:27:43.733579Z","shell.execute_reply":"2025-01-06T21:27:43.738250Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A similarity score of two embedding vectors can be obtained by calculating their inner product. If $\\mathbf{u}$ is the first embedding vector, and $\\mathbf{v}$ the second, this is $\\mathbf{u}^T \\mathbf{v}$. As these embedding vectors are normalised to unit length, this is also the cosine similarity.\n\nThis score can be computed across all embeddings through the matrix self-multiplication: `df @ df.T`.\n\nNote that the range from 0.0 (completely dissimilar) to 1.0 (completely similar) is depicted in the heatmap from dark (0.0) to light (1.0).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\n\n\n# Set up the embeddings in a dataframe.\ndf = pd.DataFrame(response['embedding'], index=truncated_texts)\n# Perform the similarity calculation\nsim = df @ df.T\n# Draw!\nsns.heatmap(sim, vmin=0, vmax=1);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:28:00.391145Z","iopub.execute_input":"2025-01-06T21:28:00.391495Z","iopub.status.idle":"2025-01-06T21:28:02.020290Z","shell.execute_reply.started":"2025-01-06T21:28:00.391461Z","shell.execute_reply":"2025-01-06T21:28:02.019032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sim['The quick brown fox jumps over the lazy dog.'].sort_values(ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T21:28:07.660180Z","iopub.execute_input":"2025-01-06T21:28:07.660904Z","iopub.status.idle":"2025-01-06T21:28:07.669754Z","shell.execute_reply.started":"2025-01-06T21:28:07.660828Z","shell.execute_reply":"2025-01-06T21:28:07.668706Z"}},"outputs":[],"execution_count":null}]}