{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:11.463285Z","iopub.execute_input":"2025-01-08T05:29:11.463674Z","iopub.status.idle":"2025-01-08T05:29:11.467662Z","shell.execute_reply.started":"2025-01-08T05:29:11.463637Z","shell.execute_reply":"2025-01-08T05:29:11.466733Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"##### Copyright 2024 Google LLC.","metadata":{}},{"cell_type":"markdown","source":"# Day 4 - Fine tuning a custom model\n\nWelcome back to the Kaggle 5-day Generative AI course!\n\nIn this notebook you will use the Gemini API to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text (a newsgroup post) into the category it belongs to (the newsgroup name).\n\nThis codelab walks you tuning a model with the API. [AI Studio](https://aistudio.google.com/app/tune) also supports creating new tuned models directly in the web UI, allowing you to quickly create and monitor models using data from Google Sheets, Drive or your own files.","metadata":{}},{"cell_type":"code","source":"%pip install -U -q 'google-generativeai>=0.8.3'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:11.473200Z","iopub.execute_input":"2025-01-08T05:29:11.473526Z","iopub.status.idle":"2025-01-08T05:29:15.461313Z","shell.execute_reply.started":"2025-01-08T05:29:11.473499Z","shell.execute_reply":"2025-01-08T05:29:15.460159Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"import google.generativeai as genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:15.463085Z","iopub.execute_input":"2025-01-08T05:29:15.463491Z","iopub.status.idle":"2025-01-08T05:29:15.467784Z","shell.execute_reply.started":"2025-01-08T05:29:15.463461Z","shell.execute_reply":"2025-01-08T05:29:15.466885Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:15.469809Z","iopub.execute_input":"2025-01-08T05:29:15.470102Z","iopub.status.idle":"2025-01-08T05:29:15.926159Z","shell.execute_reply.started":"2025-01-08T05:29:15.470077Z","shell.execute_reply":"2025-01-08T05:29:15.925145Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"for model in genai.list_models():\n    if \"createTunedModel\" in model.supported_generation_methods:\n        print(model.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:15.927714Z","iopub.execute_input":"2025-01-08T05:29:15.928069Z","iopub.status.idle":"2025-01-08T05:29:16.210780Z","shell.execute_reply.started":"2025-01-08T05:29:15.928034Z","shell.execute_reply":"2025-01-08T05:29:16.209765Z"}},"outputs":[{"name":"stdout","text":"models/gemini-1.0-pro-001\nmodels/gemini-1.5-flash-001-tuning\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"The [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\nnewsgroups_train = fetch_20newsgroups(subset=\"train\")\nnewsgroups_test = fetch_20newsgroups(subset=\"test\")\n\n# View list of class names for dataset\nnewsgroups_train.target_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:16.211862Z","iopub.execute_input":"2025-01-08T05:29:16.212214Z","iopub.status.idle":"2025-01-08T05:29:16.858691Z","shell.execute_reply.started":"2025-01-08T05:29:16.212181Z","shell.execute_reply":"2025-01-08T05:29:16.857684Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"print(newsgroups_train.data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:16.859699Z","iopub.execute_input":"2025-01-08T05:29:16.860069Z","iopub.status.idle":"2025-01-08T05:29:16.864474Z","shell.execute_reply.started":"2025-01-08T05:29:16.860034Z","shell.execute_reply":"2025-01-08T05:29:16.863530Z"}},"outputs":[{"name":"stdout","text":"From: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\nOrganization: University of Maryland, College Park\nLines: 15\n\n I was wondering if anyone out there could enlighten me on this car I saw\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\nthe front bumper was separate from the rest of the body. This is \nall I know. If anyone can tellme a model name, engine specs, years\nof production, where this car is made, history, or whatever info you\nhave on this funky looking car, please e-mail.\n\nThanks,\n- IL\n   ---- brought to you by your neighborhood Lerxst ----\n\n\n\n\n\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"## Prepare the dataset\n\nYou'll use the same pre-processing code you used for the custom model on day 2. This pre-processing removes personal information, which can be used to \"shortcut\" to known users of a forum, and formats the text to appear a bit more like regular text and less like a newsgroup post (e.g. by removing the mail headers). This normalisation allows the model to generalise to regular text and not over-depend on specific fields. If your input data is always going to be newsgroup posts, it may be helpful to leave this structure in place if they provide genuine signals.","metadata":{}},{"cell_type":"code","source":"import email\nimport re\n\nimport pandas as pd\n\n\ndef preprocess_newsgroup_row(data):\n    # Extract only the subject and body\n    msg = email.message_from_string(data)\n    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n    # Strip any remaining email addresses\n    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n    # Truncate the text to fit within the input limits\n    text = text[:40000]\n\n    return text\n\n\ndef preprocess_newsgroup_data(newsgroup_dataset):\n    # Put data points into dataframe\n    df = pd.DataFrame(\n        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n    )\n    # Clean up the text\n    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n    # Match label to target name index\n    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:16.865511Z","iopub.execute_input":"2025-01-08T05:29:16.865773Z","iopub.status.idle":"2025-01-08T05:29:16.884950Z","shell.execute_reply.started":"2025-01-08T05:29:16.865751Z","shell.execute_reply":"2025-01-08T05:29:16.883866Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Apply preprocessing to training and test datasets\ndf_train = preprocess_newsgroup_data(newsgroups_train)\ndf_test = preprocess_newsgroup_data(newsgroups_test)\n\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:16.885958Z","iopub.execute_input":"2025-01-08T05:29:16.886298Z","iopub.status.idle":"2025-01-08T05:29:20.547188Z","shell.execute_reply.started":"2025-01-08T05:29:16.886260Z","shell.execute_reply":"2025-01-08T05:29:20.546199Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                                                Text  Label  \\\n0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n\n              Class Name  \n0              rec.autos  \n1  comp.sys.mac.hardware  \n2  comp.sys.mac.hardware  \n3          comp.graphics  \n4              sci.space  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n      <td>1</td>\n      <td>comp.graphics</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n      <td>14</td>\n      <td>sci.space</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"Now sample the data. You will keep 50 rows for each category for training. Note that this is even fewer than the Keras example, as this technique (parameter-efficient fine-tuning, or PEFT) updates a relatively small number of parameters and does not require training a new model or updating the large model.","metadata":{}},{"cell_type":"code","source":"def sample_data(df, num_samples, classes_to_keep):\n    # Sample rows, selecting num_samples of each Label.\n    df = (\n        df.groupby(\"Label\")[df.columns]\n        .apply(lambda x: x.sample(num_samples))\n        .reset_index(drop=True)\n    )\n\n    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n\n    return df\n\n\nTRAIN_NUM_SAMPLES = 50\nTEST_NUM_SAMPLES = 10\n# Keep rec.* and sci.*\nCLASSES_TO_KEEP = \"^rec|^sci\"\n\ndf_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\ndf_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:20.550182Z","iopub.execute_input":"2025-01-08T05:29:20.550460Z","iopub.status.idle":"2025-01-08T05:29:20.588939Z","shell.execute_reply.started":"2025-01-08T05:29:20.550436Z","shell.execute_reply":"2025-01-08T05:29:20.587916Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## Evaluate baseline performance\n\nBefore you start tuning a model, it's good practice to perform an evaluation on the available models to ensure you can measure how much the tuning helps.\n\nFirst identify a single sample row to use for visual inspection.","metadata":{"execution":{"iopub.status.busy":"2025-01-08T05:24:07.700113Z","iopub.execute_input":"2025-01-08T05:24:07.700528Z","iopub.status.idle":"2025-01-08T05:24:07.706887Z","shell.execute_reply.started":"2025-01-08T05:24:07.700501Z","shell.execute_reply":"2025-01-08T05:24:07.705406Z"}}},{"cell_type":"code","source":"sample_idx = 0\nsample_row = preprocess_newsgroup_row(newsgroups_test.data[sample_idx])\nsample_label = newsgroups_test.target_names[newsgroups_test.target[sample_idx]]\n\nprint(sample_row)\nprint('---')\nprint('Label:', sample_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:20.590387Z","iopub.execute_input":"2025-01-08T05:29:20.590816Z","iopub.status.idle":"2025-01-08T05:29:20.597260Z","shell.execute_reply.started":"2025-01-08T05:29:20.590774Z","shell.execute_reply":"2025-01-08T05:29:20.596202Z"}},"outputs":[{"name":"stdout","text":"Need info on 88-89 Bonneville\n\n\n I am a little confused on all of the models of the 88-89 bonnevilles.\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\ndifferences are far as features or performance. I am also curious to\nknow what the book value is for prefereably the 89 model. And how much\nless than book value can you usually get them for. In other words how\nmuch are they in demand this time of year. I have heard that the mid-spring\nearly summer is the best time to buy.\n\n\t\t\tNeil Gandler\n\n---\nLabel: rec.autos\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"#Passing the text directly in as a prompt does not yield the desired results. \n#The model will attempt to respond to the message.\nbaseline_model = genai.GenerativeModel(\"gemini-1.5-flash-001\")\nresponse = baseline_model.generate_content(sample_row)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:20.598449Z","iopub.execute_input":"2025-01-08T05:29:20.598829Z","iopub.status.idle":"2025-01-08T05:29:24.775579Z","shell.execute_reply.started":"2025-01-08T05:29:20.598793Z","shell.execute_reply":"2025-01-08T05:29:24.774600Z"}},"outputs":[{"name":"stdout","text":"You're right, the 1988-89 Bonneville model designations can get confusing! Let's break down the different trims and talk about their value.\n\n**1988-1989 Bonneville Trims Explained**\n\nHere's a breakdown of the major trim levels and their key features:\n\n* **LE (Luxury Edition):** The base model, featuring comfortable cloth upholstery, power steering, and a basic sound system.\n* **SE (Special Edition):**  Slightly upgraded from the LE with additional features like power windows and locks, a slightly nicer stereo, and possibly upgraded wheels.\n* **LSE (Luxury Special Edition):**  The LSE was essentially the \"mid-range\" option,  often incorporating a more luxurious interior with leather seats, additional comfort features, and maybe even a sunroof.\n* **SSE (Sport Sedan Edition):**  Focused on sporty performance, the SSE often included a more powerful engine, firmer suspension, and sportier interior accents.\n* **SSEi (Sport Sedan Edition - Injected):** The top-of-the-line SSEi boasted the most powerful engine option, additional performance enhancements (like stiffer springs, larger brakes), and  a distinctive body kit for a more aggressive look.\n\n**Book Value and Demand**\n\n* **Book Value:** To get an accurate estimate of book value for a 1989 Bonneville, you'll need to use resources like Kelley Blue Book (KBB), Edmunds, or NADAguides. You'll need to provide the specific trim level, mileage, and condition of the vehicle to get a realistic appraisal.\n* **Price Negotiation:** The \"usual\" discount from book value is highly variable. Factors include the vehicle's overall condition, mileage, and demand in your local market.  You might expect to pay 10-20% less than book value for a clean, well-maintained car, but discounts can go much higher for vehicles needing repairs or with higher mileage.\n\n**Best Time to Buy**\n\nWhile it's true that spring and early summer are often considered prime buying season for used cars, it's not an absolute rule.  The best time to buy depends on your specific situation and the market conditions.\n\n**Key Points to Remember**\n\n* **Condition is Key:**  A well-maintained 1989 Bonneville in good condition, regardless of the trim level, will command a higher price than a neglected one.\n* **Engine Choice:**  If you want performance, the SSEi with its fuel-injected V6 is the best choice.\n* **Reliability:**  While the 1988-89 Bonnevilles were generally reliable cars, you should be prepared for potential issues associated with their age. \n* **Research:**  Before you make an offer, spend time researching the specific model you're interested in, and get it inspected by a mechanic.\n\n**Tip:** Look for a car that has been regularly maintained with a documented service history. \n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"You can use the prompt engineering techniques you have learned this week to induce the model to perform the desired task. Try some of your own ideas and see what is effective, or check out the following cells for different approaches. Note that they have different levels of effectiveness!","metadata":{}},{"cell_type":"code","source":"# Ask the model directly in a zero-shot prompt.\n\nprompt = \"From what newsgroup does the following message originate?\"\nbaseline_response = baseline_model.generate_content([prompt, sample_row])\nprint(baseline_response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:24.776559Z","iopub.execute_input":"2025-01-08T05:29:24.776896Z","iopub.status.idle":"2025-01-08T05:29:26.651445Z","shell.execute_reply.started":"2025-01-08T05:29:24.776864Z","shell.execute_reply":"2025-01-08T05:29:26.650225Z"}},"outputs":[{"name":"stdout","text":"This message most likely originates from a **Buick-specific newsgroup**, such as:\n\n* **alt.autos.buick**\n* **rec.autos.buick**\n\nThese newsgroups were popular in the late 1980s and early 1990s for car enthusiasts to discuss Buick models, including the Bonneville. The message's content, specifically asking about the differences between various trim levels (LE, SE, LSE, SSE, SSEi) and discussing book value and buying season, strongly suggests it was posted within a community focused on Buicks. \n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from google.api_core import retry\n\n# You can use a system instruction to do more direct prompting, and get a\n# more succinct answer.\n\nsystem_instruct = \"\"\"\nYou are a classification service. You will be passed input that represents\na newsgroup post and you must respond with the newsgroup from which the post\noriginates.\n\"\"\"\n\ninstructed_model = genai.GenerativeModel(\"gemini-1.5-flash-001\",\n                                         system_instruction=system_instruct)\n\nretry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n\n# If you want to evaluate your own technique, replace this function with your\n# model, prompt and other code and return the predicted answer.\ndef predict_label(post: str) -> str:\n    response = instructed_model.generate_content(post, request_options=retry_policy)\n    rc = response.candidates[0]\n\n    # Any errors, filters, recitation, etc we can mark as a general error\n    if rc.finish_reason.name != \"STOP\":\n        return \"(error)\"\n    else:\n        # Clean up the response.\n        return response.text.strip()\n\n\nprediction = predict_label(sample_row)\n\nprint(prediction)\nprint()\nprint(\"Correct!\" if prediction == sample_label else \"Incorrect.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:26.652287Z","iopub.execute_input":"2025-01-08T05:29:26.652580Z","iopub.status.idle":"2025-01-08T05:29:27.742607Z","shell.execute_reply.started":"2025-01-08T05:29:26.652554Z","shell.execute_reply":"2025-01-08T05:29:27.741488Z"}},"outputs":[{"name":"stdout","text":"rec.autos.misc\n\nIncorrect.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Now run a short evaluation using the function defined above. The test set is further sampled to ensure the experiment runs smoothly on the API's free tier. \n# In practice you would evaluate over the whole set.\n\nfrom tqdm.rich import tqdm\n\ntqdm.pandas()\n\n\n# Further sample the test data to be mindful of the free-tier quota.\ndf_baseline_eval = sample_data(df_test, 2, '.*')\n\n# Make predictions using the sampled data.\ndf_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n\n# And calculate the accuracy.\naccuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:27.743719Z","iopub.execute_input":"2025-01-08T05:29:27.744079Z","iopub.status.idle":"2025-01-08T05:29:38.440923Z","shell.execute_reply.started":"2025-01-08T05:29:27.744046Z","shell.execute_reply":"2025-01-08T05:29:38.440094Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e95532d2921476ea4cfbd6b793a1157"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tqdm/std.py:885: TqdmExperimentalWarning: rich is experimental/alpha\n  t = cls(total=total, **tqdm_kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Accuracy: 12.50%\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"df_baseline_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:38.441826Z","iopub.execute_input":"2025-01-08T05:29:38.442158Z","iopub.status.idle":"2025-01-08T05:29:38.452299Z","shell.execute_reply.started":"2025-01-08T05:29:38.442134Z","shell.execute_reply":"2025-01-08T05:29:38.451478Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                                 Text  Label  \\\n0   Manual Xmission-Advice needed...\\n\\nI have man...      7   \n1   New Mercedes Diesels \\n\\n \\nHi fellow auto ent...      7   \n2   Re: Shaft-drives and Wheelies\\n\\nIn article <>...      8   \n3   Re: Shaft-drives and Wheelies\\n\\n\\nIn a previo...      8   \n4   Ray Lankford question...\\n\\nDoes anybody know ...      9   \n5   Re: Geronimo Pena?\\n\\nIn article <1r3ejr$>,  (...      9   \n6   Re: #77's?\\n\\nIn article <1r23on$>  (\"The Logi...     10   \n7   Re: Nords 3 - Habs 2 in O.T. We was robbed!!\\n...     10   \n8   Re: Secret algorithm [Re: Clipper Chip and cry...     11   \n9   Re: Organized Lobbying for Cryptography\\n\\nIn ...     11   \n10  help me, i'm not clever! (how to make power su...     12   \n11  Re: solvent for duct-tape adhesive?\\n\\n (John ...     12   \n12  Re: Iridology - Any credence to it???\\n\\nIrido...     13   \n13  Re: A Good place for Back Surgery?\\n\\n: gary.s...     13   \n14  Combo Propulsion System!?\\n\\nHow hard or easy ...     14   \n15  U.S. Government and Science and Technolgy Inve...     14   \n\n            Class Name               Prediction  \n0            rec.autos         rec.autos.repair  \n1            rec.autos           rec.autos.misc  \n2      rec.motorcycles          rec.motorcycles  \n3      rec.motorcycles          rec.motorcycles  \n4   rec.sport.baseball      rec.sports.baseball  \n5   rec.sport.baseball      rec.sports.baseball  \n6     rec.sport.hockey        rec.sports.hockey  \n7     rec.sport.hockey        rec.sports.hockey  \n8            sci.crypt                  (error)  \n9            sci.crypt                  (error)  \n10     sci.electronics  comp.electronics.design  \n11     sci.electronics           misc.consumers  \n12             sci.med               alt.health  \n13             sci.med      misc.health.medical  \n14           sci.space       rec.space.missions  \n15           sci.space            sci.stat.math  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Manual Xmission-Advice needed...\\n\\nI have man...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n      <td>rec.autos.repair</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New Mercedes Diesels \\n\\n \\nHi fellow auto ent...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n      <td>rec.autos.misc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Re: Shaft-drives and Wheelies\\n\\nIn article &lt;&gt;...</td>\n      <td>8</td>\n      <td>rec.motorcycles</td>\n      <td>rec.motorcycles</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Re: Shaft-drives and Wheelies\\n\\n\\nIn a previo...</td>\n      <td>8</td>\n      <td>rec.motorcycles</td>\n      <td>rec.motorcycles</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ray Lankford question...\\n\\nDoes anybody know ...</td>\n      <td>9</td>\n      <td>rec.sport.baseball</td>\n      <td>rec.sports.baseball</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Re: Geronimo Pena?\\n\\nIn article &lt;1r3ejr$&gt;,  (...</td>\n      <td>9</td>\n      <td>rec.sport.baseball</td>\n      <td>rec.sports.baseball</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Re: #77's?\\n\\nIn article &lt;1r23on$&gt;  (\"The Logi...</td>\n      <td>10</td>\n      <td>rec.sport.hockey</td>\n      <td>rec.sports.hockey</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Re: Nords 3 - Habs 2 in O.T. We was robbed!!\\n...</td>\n      <td>10</td>\n      <td>rec.sport.hockey</td>\n      <td>rec.sports.hockey</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Re: Secret algorithm [Re: Clipper Chip and cry...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>(error)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Re: Organized Lobbying for Cryptography\\n\\nIn ...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>(error)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>help me, i'm not clever! (how to make power su...</td>\n      <td>12</td>\n      <td>sci.electronics</td>\n      <td>comp.electronics.design</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Re: solvent for duct-tape adhesive?\\n\\n (John ...</td>\n      <td>12</td>\n      <td>sci.electronics</td>\n      <td>misc.consumers</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Re: Iridology - Any credence to it???\\n\\nIrido...</td>\n      <td>13</td>\n      <td>sci.med</td>\n      <td>alt.health</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Re: A Good place for Back Surgery?\\n\\n: gary.s...</td>\n      <td>13</td>\n      <td>sci.med</td>\n      <td>misc.health.medical</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Combo Propulsion System!?\\n\\nHow hard or easy ...</td>\n      <td>14</td>\n      <td>sci.space</td>\n      <td>rec.space.missions</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>U.S. Government and Science and Technolgy Inve...</td>\n      <td>14</td>\n      <td>sci.space</td>\n      <td>sci.stat.math</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"## Tune a custom model\n\nIn this example you'll use tuning to help create a model that requires no prompting or system instructions and outputs succinct text from the classes you provide in the training data.\n\nThe data contains both input text (the processed posts) and output text (the category, or newsgroup), which you can use to start tuning a model.\n\nThe Python SDK for tuning supports Pandas dataframes as input, so you don't need any custom data generators or pipelines. Just specify the input and the relevant columns as the `input_key` and `output_key`.\n\nWhen calling `create_tuned_model`, you can specify model tuning hyperparameters too:\n - `epoch_count`: defines how many times to loop through the data,\n - `batch_size`: defines how many rows to process in a single step, and\n - `learning_rate`: defines the scaling factor for updating model weights at each step.\n\nYou can also choose to omit them and use the defaults. [Learn more](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) about these parameters and how they work. For this example these parameters were selected by running some tuning jobs and selecting parameters that were both effective and quick.","metadata":{}},{"cell_type":"code","source":"from collections.abc import Iterable\nimport random\n\n\n# Append a random number to the model ID so you can re-run with a higher chance\n# of creating a unique model ID.\nmodel_id = f\"newsgroup-classifier-{random.randint(10000, 99999)}\"\n\n# Upload the training data and queue the tuning job.\ntuning_op = genai.create_tuned_model(\n    \"models/gemini-1.5-flash-001-tuning\",\n    training_data=df_train,\n    input_key=\"Text\",  # the column to use as input\n    output_key=\"Class Name\",  # the column to use as output\n    id=model_id,\n    display_name=\"Newsgroup classification model\",\n    batch_size=16,\n    epoch_count=2,\n)\n\nprint(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:38.453386Z","iopub.execute_input":"2025-01-08T05:29:38.453689Z","iopub.status.idle":"2025-01-08T05:29:41.216318Z","shell.execute_reply.started":"2025-01-08T05:29:38.453664Z","shell.execute_reply":"2025-01-08T05:29:41.215200Z"}},"outputs":[{"name":"stdout","text":"newsgroup-classifier-63713\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"This has created a tuning job that will run in the background. To inspect the progress of the tuning job, run this cell to plot the current status and loss curve. Once the status reaches `ACTIVE`, tuning is complete and the model is ready to use.\n\nTuning jobs are queued, so it may look like no training steps have been taken initially but it will progress. Tuning can take upwards of 20 minutes, depending on factors like your dataset size and how busy the tuning infrastrature is. Why not treat yourself to a nice cup of tea while you wait, or come and say \"Hi!\" to [yours truly](https://discord.com/users/132124213132787712) in the group [Discord](https://discord.com/invite/kaggle).\n\nIt is safe to stop this cell at any point. It will not stop the tuning job.","metadata":{}},{"cell_type":"code","source":"import time\nimport seaborn as sns\n\n\nwhile (tuned_model := genai.get_tuned_model(f\"tunedModels/{model_id}\")).state.name != 'ACTIVE':\n\n    print(tuned_model.state)\n    time.sleep(60)\n\nprint(f\"Done! The model is {tuned_model.state.name}\")\n\n# Plot the loss curve.\nsnapshots = pd.DataFrame(tuned_model.tuning_task.snapshots)\nsns.lineplot(data=snapshots, x=\"step\", y=\"mean_loss\")\n\n# Note that the seaborn module may output warnings containing FutureWarning: use_inf_as_na option is deprecated.\n# These are expected and can be ignored.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:29:41.217302Z","iopub.execute_input":"2025-01-08T05:29:41.217645Z"}},"outputs":[{"name":"stdout","text":"State.CREATING\nState.CREATING\nState.CREATING\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Use the new model\n\nNow that you have a tuned model, try it out with custom data. You use the same API as a normal Gemini API interaction, but you specify your new model as the model name, using the `tunedModels/` prefix.","metadata":{}},{"cell_type":"code","source":"your_model = genai.GenerativeModel(f\"tunedModels/{model_id}\")\n\nnew_text = \"\"\"\nFirst-timer looking to get out of here.\n\nHi, I'm writing about my interest in travelling to the outer limits!\n\nWhat kind of craft can I buy? What is easiest to access from this 3rd rock?\n\nLet me know how to do that please.\n\"\"\"\n\nresponse = your_model.generate_content(new_text)\nprint(response.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation\n\nYou can see that the model outputs labels that correspond to those in the training data, and without any system instructions or prompting, which is already a great improvement. Now see how well it performs on the test set.\n\nNote that there is no parallelism in this example; classifying the test sub-set will take a few minutes.","metadata":{}},{"cell_type":"code","source":"def classify_text(text: str) -> str:\n    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n    response = your_model.generate_content(text, request_options=retry_policy)\n    rc = response.candidates[0]\n\n    # Any errors, filters, recitation, etc we can mark as a general error\n    if rc.finish_reason.name != \"STOP\":\n        return \"(error)\"\n    else:\n        return rc.content.parts[0].text\n\n\n# The sampling here is just to minimise your quota usage. If you can, you should\n# evaluate the whole test set with `df_model_eval = df_test.copy()`.\ndf_model_eval = sample_data(df_test, 4, '.*')\n\n\ndf_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n\naccuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Next steps\n\nNow that you have tuned a classification model, try some other tasks, like tuning a model to respond with a specific tone or style using hand-written examples (or even generated examples!). Kaggle hosts [a number of datasets](https://www.kaggle.com/datasets) you can try out.\n\nLearn about [when supervised fine-tuning is most effective](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm).\n\nAnd check out the [fine-tuning tutorial](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?hl=en&lang=python) for another example that shows a tuned model extending beyond the training data to new, unseen inputs.","metadata":{}}]}