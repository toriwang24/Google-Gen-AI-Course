{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b2d3f9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-06T21:20:51.669073Z",
     "iopub.status.idle": "2025-01-06T21:20:51.669521Z",
     "shell.execute_reply": "2025-01-06T21:20:51.669295Z"
    },
    "papermill": {
     "duration": 0.00261,
     "end_time": "2025-01-06T21:23:08.535330",
     "exception": false,
     "start_time": "2025-01-06T21:23:08.532720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Day 2 - Classifying embeddings with Keras and the Gemini API\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome back to the Kaggle 5-day Generative AI course. In this notebook, you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.\n",
    "\n",
    "This technique uses the Gemini API's embeddings as input, avoiding the need to train on text input directly, and as a result it is able to perform quite well using relatively few examples compared to training a text model from scratch.\n",
    "\n",
    "## For help\n",
    "\n",
    "**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bf2a3",
   "metadata": {
    "papermill": {
     "duration": 0.001594,
     "end_time": "2025-01-06T21:23:08.539260",
     "exception": false,
     "start_time": "2025-01-06T21:23:08.537666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Day 2 - Classifying embeddings with Keras and the Gemini API\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome back to the Kaggle 5-day Generative AI course. In this notebook, you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.\n",
    "\n",
    "This technique uses the Gemini API's embeddings as input, avoiding the need to train on text input directly, and as a result it is able to perform quite well using relatively few examples compared to training a text model from scratch.\n",
    "\n",
    "## For help\n",
    "\n",
    "**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e9a843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T21:23:08.544970Z",
     "iopub.status.busy": "2025-01-06T21:23:08.544540Z",
     "iopub.status.idle": "2025-01-06T21:23:34.731675Z",
     "shell.execute_reply": "2025-01-06T21:23:34.730267Z"
    },
    "papermill": {
     "duration": 26.192859,
     "end_time": "2025-01-06T21:23:34.733890",
     "exception": false,
     "start_time": "2025-01-06T21:23:08.541031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"google-generativeai>=0.8.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86df56d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T21:23:34.740579Z",
     "iopub.status.busy": "2025-01-06T21:23:34.740184Z",
     "iopub.status.idle": "2025-01-06T21:23:35.899375Z",
     "shell.execute_reply": "2025-01-06T21:23:35.898338Z"
    },
    "papermill": {
     "duration": 1.1649,
     "end_time": "2025-01-06T21:23:35.901429",
     "exception": false,
     "start_time": "2025-01-06T21:23:34.736529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135292f",
   "metadata": {
    "papermill": {
     "duration": 0.001902,
     "end_time": "2025-01-06T21:23:35.905777",
     "exception": false,
     "start_time": "2025-01-06T21:23:35.903875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.35162,
   "end_time": "2025-01-06T21:23:36.529295",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-06T21:23:06.177675",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
